---
license: apache-2.0
language:
  - ru
base_model: Qwen/Qwen2.5-3B
tags:
  - almaty
  - events
  - qlora
  - orpo
  - fine-tuned
  - text-generation
  - assistant
  - sxodim
pipeline_tag: text-generation
datasets:
  - custom
---

# Qwen2.5-3B Sxodim Almaty üé≠

–ú–æ–¥–µ–ª—å fine-tuned –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è—Ö –ê–ª–º–∞—Ç—ã —Å [sxodim.com](https://sxodim.com) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º QLoRA + ORPO.

## –û–ø–∏—Å–∞–Ω–∏–µ

–î—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è–º –≤ –ê–ª–º–∞—Ç—ã. –ü–æ–º–æ–≥–∞–µ—Ç –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ü–µ—Ä—Ç—ã, —Å–ø–µ–∫—Ç–∞–∫–ª–∏, –≤—ã—Å—Ç–∞–≤–∫–∏ –∏ —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è. –û—Ç–≤–µ—á–∞–µ—Ç –∂–∏–≤–æ –∏ –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏, –∫–∞–∫ –¥—Ä—É–≥.

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("rsyrlybay/qwen2.5-3b-sxodim-almaty")
tokenizer = AutoTokenizer.from_pretrained("rsyrlybay/qwen2.5-3b-sxodim-almaty")

messages = [
    {"role": "system", "content": "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è–º –≤ –ê–ª–º–∞—Ç—ã."},
    {"role": "user", "content": "–ö—É–¥–∞ —Å—Ö–æ–¥–∏—Ç—å –Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö?"}
]

text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = tokenizer([text], return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=300, temperature=0.7)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

## Training Pipeline

```
Qwen2.5-3B (base)
      ‚Üì
[SFT Training] ‚Üê 1443 Q&A –ø–∞—Ä
      ‚Üì
[ORPO Training] ‚Üê ~500 preference –ø–∞—Ä
      ‚Üì
Final Model
```

## –î–µ—Ç–∞–ª–∏ –æ–±—É—á–µ–Ω–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| Base model | Qwen/Qwen2.5-3B |
| Method | QLoRA + ORPO |
| LoRA r | 32 |
| LoRA alpha | 64 |
| SFT Dataset | 1443 Q&A –ø–∞—Ä |
| ORPO Dataset | ~500 preference –ø–∞—Ä |
| Epochs | 3 |
| Learning Rate | 2e-4 |

## –î–∞–Ω–Ω—ã–µ

–°–æ–±—Ä–∞–Ω–æ —Å [sxodim.com](https://sxodim.com):
- **104 –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è** –≤ –ê–ª–º–∞—Ç—ã
- –ö–æ–Ω—Ü–µ—Ä—Ç—ã, —Å—Ç–µ–Ω–¥–∞–ø—ã, —Å–ø–µ–∫—Ç–∞–∫–ª–∏, –º—é–∑–∏–∫–ª—ã, –≤—ã—Å—Ç–∞–≤–∫–∏, –¥–µ—Ç—Å–∫–∏–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è
- –ê–¥—Ä–µ—Å–∞, —Ü–µ–Ω—ã, –¥–∞—Ç—ã, –æ–ø–∏—Å–∞–Ω–∏—è

## –ü—Ä–∏–º–µ—Ä—ã

**User:** –ö–∞–∫–∏–µ –∫–æ–Ω—Ü–µ—Ä—Ç—ã –±—É–¥—É—Ç –≤ —ç—Ç–∏ –≤—ã—Ö–æ–¥–Ω—ã–µ?

**Assistant:** –û, –≤ —ç—Ç–∏ –≤—ã—Ö–æ–¥–Ω—ã–µ –º–Ω–æ–≥–æ –∫—Ä—É—Ç–æ–≥–æ! –°–æ–≤–µ—Ç—É—é –∑–∞–≥–ª—è–Ω—É—Ç—å –Ω–∞ —Å—Ç–µ–Ω–¥–∞–ø –≤ Punch Stand Up Club ‚Äî —Ç–∞–º –≤—Å–µ–≥–¥–∞ —É–≥–∞—Ä. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å —á—Ç–æ-—Ç–æ –º—É–∑—ã–∫–∞–ª—å–Ω–æ–µ, –ø–æ—Å–º–æ—Ç—Ä–∏ –∞—Ñ–∏—à—É EverJazz, —É –Ω–∏—Ö —á–∞—Å—Ç–æ –±—ã–≤–∞—é—Ç –¥–∂–∞–∑–æ–≤—ã–µ –≤–µ—á–µ—Ä–∞. –ê –¥–ª—è –¥–µ—Ç–µ–π –µ—Å—Ç—å –º—é–∑–∏–∫–ª—ã –≤ —Ä–∞–∑–Ω—ã—Ö —Ç–µ–∞—Ç—Ä–∞—Ö –≥–æ—Ä–æ–¥–∞!

---

**User:** –ì–¥–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å—Ç–µ–Ω–¥–∞–ø –≤ –ê–ª–º–∞—Ç—ã?

**Assistant:** –°–∞–º–æ–µ —Ç–æ–ø–æ–≤–æ–µ –º–µ—Å—Ç–æ ‚Äî —ç—Ç–æ Punch Stand Up Club! –¢–∞–º –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –≤—ã—Å—Ç—É–ø–∞—é—Ç –∏ –º–µ—Å—Ç–Ω—ã–µ –∫–æ–º–∏–∫–∏, –∏ –ø—Ä–∏–µ–∑–∂–∏–µ –∑–≤—ë–∑–¥—ã. –ê—Ç–º–æ—Å—Ñ–µ—Ä–∞ –∫–ª–∞—Å—Å–Ω–∞—è, –∑–∞–ª —É—é—Ç–Ω—ã–π. –ë–∏–ª–µ—Ç—ã –æ–±—ã—á–Ω–æ –æ—Ç 5000 —Ç–µ–Ω–≥–µ, –Ω–æ –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–∏–∫–æ–≤ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ—Ä–æ–∂–µ. –û—á–µ–Ω—å —Ä–µ–∫–æ–º–µ–Ω–¥—É—é!

## Links

- **Training Notebook:** [Google Colab](https://colab.research.google.com/drive/1mVQa-dxBqTnVnDGmB5aD8FVps9q8bhmb?usp=sharing)
- **Data Source:** [sxodim.com](https://sxodim.com)

## –ê–≤—Ç–æ—Ä

nFactorial Incubator 2025

## –õ–∏—Ü–µ–Ω–∑–∏—è

Apache 2.0
